
epoch:  0 , example:  1  current loss =  0.30736544728279114
epoch:  0 , example:  2  current loss =  0.11517331749200821
epoch:  0 , example:  3  current loss =  0.20306888222694397
epoch:  0 , example:  4  current loss =  0.12798461318016052
epoch:  0 , example:  5  current loss =  0.09310121089220047
epoch:  0 , example:  6  current loss =  0.06418490409851074
epoch:  0 , example:  7  current loss =  0.053413499146699905
epoch:  0 , example:  8  current loss =  0.051122765988111496
epoch:  0 , example:  9  current loss =  0.060697294771671295
epoch:  0 , example:  10  current loss =  0.043657999485731125
epoch:  0 , example:  11  current loss =  0.028680825605988503
epoch:  0 , example:  12  current loss =  0.027352148666977882
epoch:  0 , example:  13  current loss =  0.029736969619989395
epoch:  0 , example:  14  current loss =  0.03287471458315849
epoch:  0 , example:  15  current loss =  0.023580217733979225
epoch:  0 , example:  16  current loss =  0.020077422261238098
epoch:  0 , example:  17  current loss =  0.03244321048259735
epoch:  0 , example:  18  current loss =  0.03033406287431717
epoch:  0 , example:  19  current loss =  0.024226348847150803
epoch:  0 , example:  20  current loss =  0.02698836289346218
epoch:  0 , example:  21  current loss =  0.02561691217124462
epoch:  0 , example:  22  current loss =  0.023913679644465446
epoch:  0 , example:  23  current loss =  0.02731924131512642
epoch:  0 , example:  24  current loss =  0.023820720613002777
epoch:  0 , example:  25  current loss =  0.024835528805851936
epoch:  0 , example:  26  current loss =  0.020665815100073814
epoch:  0 , example:  27  current loss =  0.02527272328734398
epoch:  0 , example:  28  current loss =  0.023386474698781967
epoch:  0 , example:  29  current loss =  0.03198624774813652
epoch:  0 , example:  30  current loss =  0.02622564323246479
epoch:  0 , example:  31  current loss =  0.032208286225795746
epoch:  0 , example:  32  current loss =  0.02985837124288082
epoch:  0 , example:  33  current loss =  0.04564538598060608
epoch:  0 , example:  34  current loss =  0.016958067193627357
epoch:  0 , example:  35  current loss =  0.023301880806684494
epoch:  0 , example:  36  current loss =  0.02378956228494644
epoch:  0 , example:  37  current loss =  0.024450311437249184
epoch:  0 , example:  38  current loss =  0.02609541267156601
epoch:  0 , example:  39  current loss =  0.019265402108430862
epoch:  0 , example:  40  current loss =  0.02329380251467228
epoch:  0 , example:  41  current loss =  0.019290439784526825
epoch:  0 , example:  42  current loss =  0.014670168980956078
epoch:  0 , example:  43  current loss =  0.01951187290251255
epoch:  0 , example:  44  current loss =  0.024351952597498894
epoch:  0 , example:  45  current loss =  0.01943582110106945
epoch:  0 , example:  46  current loss =  0.06359761208295822
epoch:  0 , example:  47  current loss =  0.01900525391101837
epoch:  0 , example:  48  current loss =  0.023889489471912384
epoch:  0 , example:  49  current loss =  0.017264001071453094
epoch:  0 , example:  50  current loss =  0.022732196375727654
epoch:  0 , example:  51  current loss =  0.017674289643764496
epoch:  0 , example:  52  current loss =  0.03625798225402832
epoch:  0 , example:  53  current loss =  0.020129980519413948
epoch:  0 , example:  54  current loss =  0.022332871332764626
epoch:  0 , example:  55  current loss =  0.019363993778824806
epoch:  0 , example:  56  current loss =  0.014773748815059662
epoch:  0 , example:  57  current loss =  0.019295917823910713
epoch:  0 , example:  58  current loss =  0.02607753686606884
epoch:  0 , example:  59  current loss =  0.022323258221149445
epoch:  0 , example:  60  current loss =  0.025486886501312256
epoch:  0 , example:  61  current loss =  0.020394165068864822
epoch:  0 , example:  62  current loss =  0.022046051919460297
epoch:  0 , example:  63  current loss =  0.01488312054425478
epoch:  0 , example:  64  current loss =  0.02211024984717369
epoch:  0 , example:  65  current loss =  0.03696494922041893
epoch:  0 , example:  66  current loss =  0.02388441003859043
epoch:  0 , example:  67  current loss =  0.02912634238600731
epoch:  0 , example:  68  current loss =  0.016254641115665436
epoch:  0 , example:  69  current loss =  0.01979350857436657
epoch:  0 , example:  70  current loss =  0.028271710500121117
epoch:  0 , example:  71  current loss =  0.019032282754778862
epoch:  0 , example:  72  current loss =  0.024135230109095573
epoch:  0 , example:  73  current loss =  0.030800191685557365
epoch:  0 , example:  74  current loss =  0.022243529558181763
epoch:  0 , example:  75  current loss =  0.019694842398166656
epoch:  0 , example:  76  current loss =  0.03801649063825607
epoch:  0 , example:  77  current loss =  0.021817801520228386
epoch:  0 , example:  78  current loss =  0.023546438664197922
epoch:  0 , example:  79  current loss =  0.0284174345433712
epoch:  0 , example:  80  current loss =  0.021445835009217262
epoch:  0 , example:  81  current loss =  0.020363416522741318
epoch:  0 , example:  82  current loss =  0.02519361861050129
epoch:  0 , example:  83  current loss =  0.023774676024913788
epoch:  0 , example:  84  current loss =  0.029507506638765335
epoch:  0 , example:  85  current loss =  0.02446288987994194
epoch:  0 , example:  86  current loss =  0.01850781962275505
epoch:  0 , example:  87  current loss =  0.026656290516257286
epoch:  0 , example:  88  current loss =  0.029697604477405548
epoch:  0 , example:  89  current loss =  0.02605487033724785
epoch:  0 , example:  90  current loss =  0.01872604712843895
epoch:  0 , example:  91  current loss =  0.018851879984140396
epoch:  0 , example:  92  current loss =  0.01766957715153694
epoch:  0 , example:  93  current loss =  0.01941787265241146
epoch:  0 , example:  94  current loss =  0.021756356582045555
epoch:  0 , example:  95  current loss =  0.020224880427122116
epoch:  0 , example:  96  current loss =  0.020370127633213997
epoch:  0 , example:  97  current loss =  0.018603898584842682
epoch:  0 , example:  98  current loss =  0.01670016534626484
epoch:  0 , example:  99  current loss =  0.013561628758907318
epoch:  0 , example:  100  current loss =  0.024492857977747917
epoch:  0 , example:  101  current loss =  0.01937127113342285
epoch:  0 , example:  102  current loss =  0.01924886740744114
epoch:  0 , example:  103  current loss =  0.01783195324242115
epoch:  0 , example:  104  current loss =  0.017825370654463768
epoch:  0 , example:  105  current loss =  0.017494428902864456
epoch:  0 , example:  106  current loss =  0.029993779957294464
epoch:  0 , example:  107  current loss =  0.01506751123815775
epoch:  0 , example:  108  current loss =  0.02278939262032509
epoch:  0 , example:  109  current loss =  0.022864388301968575
epoch:  0 , example:  110  current loss =  0.021461719647049904
epoch:  0 , example:  111  current loss =  0.034033674746751785
epoch:  0 , example:  112  current loss =  0.0306236632168293
epoch:  0 , example:  113  current loss =  0.031301770359277725
epoch:  0 , example:  114  current loss =  0.025569315999746323
epoch:  0 , example:  115  current loss =  0.023227250203490257
epoch:  0 , example:  116  current loss =  0.02251984365284443
epoch:  0 , example:  117  current loss =  0.02277383580803871
epoch:  0 , example:  118  current loss =  0.01779864728450775
epoch:  0 , example:  119  current loss =  0.026120098307728767
epoch:  0 , example:  120  current loss =  0.020102374255657196
epoch:  0 , example:  121  current loss =  0.02259436994791031
epoch:  0 , example:  122  current loss =  0.02124515362083912
epoch:  0 , example:  123  current loss =  0.01785586029291153
epoch:  0 , example:  124  current loss =  0.024603763595223427
epoch:  0 , example:  125  current loss =  0.020018966868519783
epoch:  0 , example:  126  current loss =  0.011632788926362991
epoch:  0 , example:  127  current loss =  0.017992572858929634
epoch:  0 , example:  128  current loss =  0.01871335878968239
epoch:  0 , example:  129  current loss =  0.021325314417481422
epoch:  0 , example:  130  current loss =  0.022097036242485046
epoch:  0 , example:  131  current loss =  0.024510344490408897
epoch:  0 , example:  132  current loss =  0.01565777324140072
epoch:  0 , example:  133  current loss =  0.01943279430270195
epoch:  0 , example:  134  current loss =  0.02646857313811779
epoch:  0 , example:  135  current loss =  0.03132927417755127
epoch:  0 , example:  136  current loss =  0.027090616524219513
epoch:  0 , example:  137  current loss =  0.033926840871572495
epoch:  0 , example:  138  current loss =  0.016640162095427513
epoch:  0 , example:  139  current loss =  0.02656581997871399
epoch:  0 , example:  140  current loss =  0.027020303532481194
epoch:  0 , example:  141  current loss =  0.023247038945555687
epoch:  0 , example:  142  current loss =  0.025092363357543945
epoch:  0 , example:  143  current loss =  0.022839050740003586
epoch:  0 , example:  144  current loss =  0.019750583916902542
epoch:  0 , example:  145  current loss =  0.027891958132386208
epoch:  0 , example:  146  current loss =  0.018546923995018005
epoch:  0 , example:  147  current loss =  0.025089915841817856
epoch:  0 , example:  148  current loss =  0.02149318903684616
epoch:  0 , example:  149  current loss =  0.022686559706926346
epoch:  0 , example:  150  current loss =  0.027343163266777992
epoch:  0 , example:  151  current loss =  0.02624923177063465
epoch:  0 , example:  152  current loss =  0.0284673273563385
epoch:  0 , example:  153  current loss =  0.029360337182879448
epoch:  0 , example:  154  current loss =  0.03673937916755676
epoch:  0 , example:  155  current loss =  0.020101189613342285
epoch:  0 , example:  156  current loss =  0.027864620089530945
epoch:  0 , example:  157  current loss =  0.027409804984927177
epoch:  0 , example:  158  current loss =  0.019481061026453972
epoch:  0 , example:  159  current loss =  0.02016889676451683
epoch:  0 , example:  160  current loss =  0.02354048378765583
epoch:  0 , example:  161  current loss =  0.01916591450572014
epoch:  0 , example:  162  current loss =  0.0192277692258358
epoch:  0 , example:  163  current loss =  0.018234586343169212
epoch:  0 , example:  164  current loss =  0.02133905701339245
epoch:  0 , example:  165  current loss =  0.03321966528892517
epoch:  0 , example:  166  current loss =  0.021529894322156906
epoch:  0 , example:  167  current loss =  0.02709943614900112
epoch:  0 , example:  168  current loss =  0.020523427054286003
epoch:  0 , example:  169  current loss =  0.021564260125160217
epoch:  0 , example:  170  current loss =  0.021479591727256775
epoch:  0 , example:  171  current loss =  0.025076093152165413
epoch:  0 , example:  172  current loss =  0.02043081633746624
epoch:  0 , example:  173  current loss =  0.022692136466503143
epoch:  0 , example:  174  current loss =  0.019061362370848656
epoch:  0 , example:  175  current loss =  0.020494427531957626
epoch:  0 , example:  176  current loss =  0.02350665256381035
epoch:  0 , example:  177  current loss =  0.027841171249747276
epoch:  0 , example:  178  current loss =  0.014825895428657532
epoch:  0 , example:  179  current loss =  0.034468039870262146
epoch:  0 , example:  180  current loss =  0.017843537032604218
epoch:  0 , example:  181  current loss =  0.02446458674967289
Traceback (most recent call last):
  File "c:\Users\joaqu\OneDrive\Documentos\FAU\Project glaciar\Glaciers_NeurIPS\DeepLearning\LSTMTrain\LSTMTrain.py", line 37, in <module>
    functions.trainLoop(dataTrain, dataVal,  model, loss, False, "LSTMEncDec", params, True, device)
  File "c:\Users\joaqu\OneDrive\Documentos\FAU\Project glaciar\Glaciers_NeurIPS\DeepLearning\LSTMTrain\functions.py", line 586, in trainLoop
    optimizer.step()
  File "C:\Users\joaqu\anaconda3\envs\glaciar\Lib\site-packages\torch\optim\optimizer.py", line 280, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\joaqu\anaconda3\envs\glaciar\Lib\site-packages\torch\optim\optimizer.py", line 33, in _use_grad
    ret = func(self, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\joaqu\anaconda3\envs\glaciar\Lib\site-packages\torch\optim\adamw.py", line 171, in step
    adamw(
  File "C:\Users\joaqu\anaconda3\envs\glaciar\Lib\site-packages\torch\optim\adamw.py", line 321, in adamw
    func(
  File "C:\Users\joaqu\anaconda3\envs\glaciar\Lib\site-packages\torch\optim\adamw.py", line 440, in _single_tensor_adamw
    denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt